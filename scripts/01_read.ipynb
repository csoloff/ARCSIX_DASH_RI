{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_read(path):\n",
    "    '''\n",
    "    Reads .ict files to a Pandas DataFrame\n",
    "    :param path: path to the .ict data\n",
    "    :return: Pandas DataFrame with .ict data\n",
    "    '''\n",
    "    with open(path) as f:\n",
    "        # find the value in the file which tells you how many lines to skip to get to the table\n",
    "        first_line = f.readline()\n",
    "        header_line = int(first_line[0:-2].split(\",\")[0])-1\n",
    "    data = pd.read_csv(path, sep=',', skiprows=header_line)\n",
    "\n",
    "    # finds the location in the path containing the date\n",
    "    acc = 0\n",
    "    boo = False\n",
    "    for letter in path:\n",
    "        if letter == '2':\n",
    "            boo = True\n",
    "        elif boo and letter == '0':\n",
    "            acc -= 1\n",
    "            break\n",
    "        acc += 1\n",
    "        \n",
    "    # creates datetime object with the date the data was collected\n",
    "    day = dt(int(path[acc:acc+4]), int(path[acc+4:acc+6]), int(path[acc+6:acc+8])) \n",
    "    \n",
    "    for column in data.keys():\n",
    "        if 'Time' in column:\n",
    "            # converts seconds after midnight columns to datetime\n",
    "            data[column] = day + pd.to_timedelta(data[column], unit='seconds')\n",
    "    data.columns = data.columns.str.replace(' ', '')\n",
    "    return data.replace(-9999, np.nan) # Converts -9999 values to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_instr(instr, subset = None):\n",
    "    paths = sorted(glob.glob('../data/*'+instr+'*'))\n",
    "    d_list = []\n",
    "    for i in range(0, len(paths)):\n",
    "        d_list.append(simple_read(paths[i]))\n",
    "    d = pd.concat(d_list).reset_index(drop=True)\n",
    "    if subset:\n",
    "        d = d.dropna(subset = subset, how='all').reset_index(drop=True)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RI = read_instr('DASH', ['RI', 'GF'])\n",
    "AMS = read_instr('AMS')\n",
    "OPT = read_instr('OPT')\n",
    "MetNav = read_instr('MetNav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(d1, d2, n_jobs=-1):\n",
    "\n",
    "    def row_mean(d1_row, d2, vars):\n",
    "        # Filter d2 based on the time range in d1_row\n",
    "        sub = d2[(d2['Time_Start'] >= d1_row['Time_Start']) & (d2['Time_Stop'] <= d1_row['Time_Stop'])].mean()\n",
    "        # Return the index and the computed values\n",
    "        return sub[vars]\n",
    "    \n",
    "    def row_mean_single_time(d1_row, d2, vars, time_key):\n",
    "        # Filter d2 based on the time range in d1_row\n",
    "        sub = d2[(d2[time_key] >= d1_row['Time_Start']) & (d2[time_key] < d1_row['Time_Stop'])].mean()\n",
    "        # Return the index and the computed values\n",
    "        return sub[vars]\n",
    "\n",
    "\n",
    "    # Get the list of variables to merge (excluding 'Time' related columns)\n",
    "    vars = [var for var in d2.keys() if 'Time' not in var]\n",
    "    \n",
    "    if 'Time_Start' and 'Time_Stop' in d2.keys():\n",
    "        # Use joblib to parallelize the processing of each row in d1\n",
    "        m = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(row_mean)(d1_row, d2, vars) for _, d1_row in tqdm(d1.iterrows(), total = len(d1))\n",
    "        )\n",
    "    else:\n",
    "        time_key = [var for var in d2.keys() if 'Time' in var][0]\n",
    "        m = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(row_mean_single_time)(d1_row, d2, vars, time_key) for _, d1_row in tqdm(d1.iterrows(), total = len(d1))\n",
    "        )\n",
    "\n",
    "    m = pd.concat(m, axis=1).T\n",
    "    out = pd.merge(d1, m, left_index=True, right_index=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31681/31681 [00:08<00:00, 3939.06it/s]\n",
      "100%|██████████| 31681/31681 [00:07<00:00, 4071.59it/s]\n",
      "100%|██████████| 31681/31681 [01:40<00:00, 315.25it/s]\n"
     ]
    }
   ],
   "source": [
    "d = merge_data(RI, AMS)\n",
    "d = merge_data(d, OPT)\n",
    "d = merge_data(d, MetNav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dates to datetime objects for comparison\n",
    "target_dates = ['5/24/2024', '6/17/2024', '7/22/2024', '08/16/2024']\n",
    "target_dates = pd.to_datetime(target_dates).date\n",
    "\n",
    "# Set 'TF' to 1 where 'Time_Mid' is in the target dates\n",
    "d['TF'] = d['Time_Mid'].dt.date.isin(target_dates).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding some calculated variables\n",
    "d['AMS_tot'] = d[['Org_AMS_STP', 'SO4_AMS_STP', 'NO3_AMS_STP', 'NH4_AMS_STP', 'Chl_AMS_STP']].sum(axis=1)\n",
    "d['OMF'] = d['Org_AMS_STP'] / d['AMS_tot']\n",
    "d['SMF'] = d['SO4_AMS_STP'] / d['AMS_tot']\n",
    "d['NMF'] = d['NO3_AMS_STP'] / d['AMS_tot']\n",
    "d['AMF'] = d['NH4_AMS_STP'] / d['AMS_tot']\n",
    "d['s_after_midnight'] = (d.Time_Mid - d.Time_Mid.dt.normalize()).dt.total_seconds()\n",
    "d.loc[d['Time_Mid']<'2024-07-01', 'season'] = 'spr'\n",
    "d.loc[d['Time_Mid']>'2024-07-01', 'season'] = 'sum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv('../tables/d.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
